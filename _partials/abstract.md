---
title: Abstract
layout: default
---
# Abstract

The goal of this research is to present an analysis around the ongoing project Czech-IT!, a corpus based on a quantitative analysis of Czech native learners which are acquiring the Italian language. Different kinds of texts are proposed: email communication for (quasi-) bureaucratic language analysis, informal text messages and spoken language investigations. 
NLP and automated tools are used in order to retrieve morphological, syntactical and POS information about the texts.

Learner's native language (L1) conditionates deeply the way in which the acquisitional path towards a target language (L2) is conducted, often revealing structures
which are present in the L1 grammar, while not in the L2. This sort of learning path shed a light upon some variations in linguistic endowment of two different
grammar an can offer a privileged point of view about a quantitative analysis on the range of variation between two different languages.

<p>Studies on Second Language Acquisition (SLA) is a fertile field, either both from an applied view [8] than by theoretically grounded perspective [9], which relies on comparative and contrastive analyses of linguistic phenomena. The usage of computational machinery and digital architecture [6, 11, 14] represents a standpoint in the current path of linguistic studies, resulting in a highly interdisciplinary model to researching.

<p>The data are inserted at first in textual forms, where are stored the relevant informations about the learner, the date and notes of the revisor, while the textual content of each relevant example is processed towards the usage of automatic machinery, which yields syntactical, morphological and part of speech tagging an-
notations, relevant for quantitative and statistical outcomes. 
Separating the raw data from the annotation scheme seems to be a feasible way to retain data in a wide output directions, e.g. for data-visualization outcomes, and can be effectively implemented towards the successive implementation without the necessity to rethink the overall platform. Also, it permits to data to be independent from contingent purposes and easily accessible and used by the whole community of scholars, researchers, and interested users.
It could be usable for data-driven approaches to learning second language andfor theoretically-oriented researches on interlanguage, syntactic variation and computational linguistics.

The usage of automatic procedures to analyze the natural languages is involved in the digital and computational machinery: NLP tools provide for a tokenization of the entire corpus and the words count, as well than for POS-tagging and lemmatization. This permits to obtain a wide range of data for each text.